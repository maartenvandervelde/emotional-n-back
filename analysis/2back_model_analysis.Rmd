---
title: "Emotional 2-back model analysis"
author: "Maarten van der Velde"
date: "January 2018"
output: 
  html_document:
    toc: TRUE
    highlight: tango
    smart: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
```

## Setup
```{r}
library(tidyverse)
library(httr) # Enables OSF data storage:  dat <- GET("osf.io/x6fud/?action=download", progress()) %>% content(as = "parsed")
library(magrittr)
library(stringr)
library(scales)
library(forcats)
library(qgraph)
library(tikzDevice)
options("tikzDocumentDeclaration" = "\\documentclass[12pt]{article}\n") # Default is 10pt.

use_tikz = FALSE # set to TRUE to save .tex versions of the plots

data_path <- "/Users/maarten/Dropbox (Work)/Masterproject/emotional-n-back/data/2back/"
fig_path <- "/Users/maarten/Dropbox(Work)/Masterproject/emotional-n-back/fig/"

# Plot groups
data_names = c("control", "depressed")
model_names = c("control model", "depressed model")
plot_groups = c(rbind(data_names, model_names))

# Plot theming
plot_theme <- theme_bw()

# Custom colour scale for plots
group_colours <- c("#5f91e2", "#5fc5e2", "#c4912d", "#e2ba5f")
names(group_colours) <- plot_groups
fill_scale <- scale_fill_manual(name = "", values = group_colours)

```

## Reading in the data

### Empirical data from Levens & Gotlib (2010)
```{r}
lgdat <- read.csv(paste0(data_path, "lgdat_2back.csv"))
```

### Model data
```{r}
control_dir <- paste0(data_path, "20180119b")
depressed_dir <- paste0(data_path, "20180118e")

beh_files <- c()
beh_files[1] <- tail(list.files(path = control_dir, pattern="beh.csv", full.names = TRUE),1)
beh_files[2] <- tail(list.files(path = depressed_dir, pattern="beh.csv", full.names = TRUE),1)

behdat_full <- data.frame()
for (i in 1:length(beh_files)) {
  behdat_full <- rbind(behdat_full, read.csv(beh_files[i], header=TRUE,sep=","))
}

behdat <- behdat_full %>%
  mutate(type = ifelse(model == levels(model)[1], model_names[1], model_names[2])) %>%
  select(-model, -task_rep)

# Add outcome and condition of trial (see Levens and Gotlib (2010))
outcome <- rep("", nrow(behdat))
condition <- rep("", nrow(behdat))
valence <- behdat$stimulus

for (i in 1:nrow(behdat)) {
  
  # The first two trials of each block are discarded, no 2-back exists in either
  if (behdat[i,]$trial %% 55 %in% 1:2) {
    outcome[i] <- "none"
    condition[i] <- "none"
  } else {
    expected_answer <- ifelse(behdat[i,]$stimulus == behdat[i-2,]$stimulus, "same", "diff")
    outcome[i] <- ifelse(behdat[i,]$response == expected_answer, "correct", "wrong")
    
    if (expected_answer == "same") {
      # Match-set trial (same stimulus as two trials ago)
      condition[i] <- "match"
    } else {
      if (condition[i-1] == "match") {
        if (behdat[i-1,]$stimulus == behdat[i,]$stimulus) {
          # Perseverance-set trial (diff. than 2-back, but same as match-set in previous trial)
          condition[i] <- "pers"
        } else {
          # Break-set trial (diff. than 2-back, and diff. than match-set in previous trial)
          condition[i] <- "break"
          
          # In this case, the relevant valence is that of the broken set, not the current stimulus
          valence[i] <- valence[i-1] 
        }
      } else {
        condition[i] <- "noset"
      }
    }
  }
}

behdat$outcome <- as.factor(outcome)
behdat$condition <- as.factor(condition)
behdat$valence <- as.factor(valence)

behdat$accuracy <- behdat$outcome == "correct"
behdat$responded <- behdat$outcome %in% c("correct", "wrong") & between(behdat$rt, 0, 2.0) & behdat$response != "none"

behdat_filtered <- behdat %>%
  filter(response != "none") %>% # Filter out non-responses
  filter(rt <= 2.0) %>%   # Responses after 2s are too late
  filter(rt > 0) %>%      # Response times of 0s indicate missed trials
  filter(outcome != "none") %>% # Non-response trials at the start of each block

  # Filter out trials with extreme RTs (outside 2.5 SDs of each participant's mean RT)
  group_by(type, participant) %>%
  mutate(rt_mean = mean(rt), rt_sd = sd(rt)) %>%
  filter(rt >= rt_mean - 2.5 * rt_sd, rt <= rt_mean + 2.5 * rt_sd)

```


## Accuracy
```{r}
accdat_model <- behdat_filtered %>%
  group_by(participant, type, condition, valence) %>%
  summarise(acc = mean(accuracy)) %>%
  group_by(type, condition, valence) %>%
  summarise(acc_mean = mean(acc), acc_sd = sd(acc))

accdat_lg <- lgdat %>%
  rename(valence = expression) %>%
  mutate(acc_sd = NA) %>%
  select(valence, condition, acc_mean, acc_sd, type)

accdat_all <- rbind(accdat_lg, data.frame(accdat_model)) %>%
  mutate(type = fct_relevel(type, plot_groups))


if (use_tikz) {
  tikz(file = paste0(fig_path, "2backAccuracyByCondition.tex"), width = 6, height = 3)
}

p <- ggplot(accdat_all, aes(x = valence, y = acc_mean, group = type, fill = type)) +
  facet_grid(~condition, labeller = labeller(condition = c("break" = "break-set", match = "match-set", noset = "no-set", pers = "perseverance-set"))) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  scale_y_continuous() +
  geom_errorbar(aes(ymin=acc_mean-acc_sd, ymax=acc_mean+acc_sd), width=0.2, position = position_dodge(width = 0.9)) +
  labs(x = "Condition", y = "Mean accuracy") +
  fill_scale +
  plot_theme

print(p)
if (use_tikz) {
  dev.off()
}


```

### ANOVA
```{r}
acc_break <- behdat_filtered %>%
  filter(condition == "break")

summary(aov(accuracy ~ (type * valence), data = acc_break))

acc_match <- behdat_filtered %>%
  filter(condition == "match")

summary(aov(accuracy ~ (type * valence), data = acc_match))

acc_noset <- behdat_filtered %>%
  filter(condition == "noset")

summary(aov(accuracy ~ (type * valence), data = acc_noset))

acc_pers <- behdat_filtered %>%
  filter(condition == "pers")

summary(aov(accuracy ~ (type * valence), data = acc_pers))

```

### Correlation with data
```{r}
acc_model <- accdat_model %>%
  arrange(type, condition, valence) %>%
  pull(acc_mean)

acc_data <- accdat_lg %>%
  arrange(type, condition, valence) %>%
  pull(acc_mean)

cor(acc_model, acc_data)

```

## Response rate
```{r}
respdat_model <- behdat %>%
  group_by(type, participant, condition, valence, responded) %>%
  tally() %>%
  group_by(type, participant, condition, valence) %>%
  mutate(freq = n/sum(n)) %>% # Represent as fraction
  filter(responded == TRUE) %>%
  select(-responded, -n) %>%
  group_by(type, condition, valence) %>%
  summarise(rr_mean = mean(freq), rr_sd = sd(freq))

respdat_lg <- lgdat %>%
  mutate(rr_sd = NA) %>%
  rename(valence = expression) %>%
  select(condition, valence, rr_mean, rr_sd, type)

respdat_all <- rbind(respdat_lg, data.frame(respdat_model)) %>%
  mutate(type = fct_relevel(type, plot_groups))


if (use_tikz) {
  tikz(file = paste0(fig_path, "2backResponseRate.tex"), width = 6, height = 3)
}
p <- ggplot(respdat_all, aes(x = valence, y = rr_mean, group = type, fill = type)) +
  facet_grid(~condition, labeller = labeller(condition = c("break" = "break-set", match = "match-set", noset = "no-set", pers = "perseverance-set"))) +
  geom_bar(stat = "identity", position=position_dodge(width=0.9)) +
  scale_y_continuous() +
  geom_errorbar(aes(ymin=rr_mean-rr_sd, ymax=rr_mean+rr_sd), width=0.2, position = position_dodge(width = 0.9)) +
  labs(x = "Condition", y = "Response rate") +
  fill_scale + 
  plot_theme

print(p)
if (use_tikz) {
  dev.off()
}
```

### ANOVA
```{r}
rr_break <- behdat %>%
  filter(condition == "break")

summary(aov(responded ~ (type * valence), data = rr_break))

rr_match <- behdat %>%
  filter(condition == "match")

summary(aov(responded ~ (type * valence), data = rr_match))

rr_noset <- behdat %>%
  filter(condition == "noset")

summary(aov(responded ~ (type * valence), data = rr_noset))

rr_pers <- behdat %>%
  filter(condition == "pers")

summary(aov(responded ~ (type * valence), data = rr_pers))

```

### Correlation with data
```{r}
rr_model <- respdat_model %>%
  arrange(type, condition, valence) %>%
  pull(rr_mean)

rr_data <- respdat_lg %>%
  arrange(type, condition, valence) %>%
  pull(rr_mean)

cor(rr_model, rr_data)
```

## Response time
```{r}
rtdat_model <- behdat_filtered %>%
  filter(outcome == "correct") %>%
  group_by(type, participant, condition, valence) %>%
  summarise(rt = mean(rt)) %>%
  group_by(type, condition, valence) %>%
  summarise(rt_mean = mean(rt), rt_sd = sd(rt))

rtdat_lg <- lgdat %>%
  rename(valence = expression) %>%
  select(condition, valence, rt_mean, rt_sd, type)

rtdat_all <- rbind(rtdat_lg, data.frame(rtdat_model)) %>%
  mutate(type = fct_relevel(type, plot_groups))

if (use_tikz) {
  tikz(file = paste0(fig_path, "2backResponseTime.tex"), width = 6, height = 3)
}

p <- ggplot(rtdat_all, aes(x = valence, y = rt_mean, group = type, fill= type)) +
  facet_grid(~condition, labeller = labeller(condition = c("break" = "break-set", match = "match-set", noset = "no-set", pers = "perseverance-set"))) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  scale_y_continuous() +
  geom_errorbar(aes(ymin=rt_mean-rt_sd, ymax=rt_mean+rt_sd), width=0.2, position = position_dodge(width = 0.9)) +
  labs(x = "Condition", y = "Mean RT (s)") +
  fill_scale +
  plot_theme

print(p)
if (use_tikz) {
  dev.off()
}
```

## z-transformed response time
```{r}
behdat_filtered_z_rt <- behdat_filtered %>%
  select(-rt_mean, -rt_sd) %>%
  filter(outcome == "correct") %>%
  group_by(participant, type) %>%
  mutate(overall_rt = mean(rt)) %>%
  group_by(participant, type, condition, valence, overall_rt) %>%
  mutate(condition_rt = mean(rt), condition_rt_sd = sd(rt)) %>%
  mutate(z_rt = (condition_rt - overall_rt) / condition_rt_sd)

z_rtdat_model <- behdat_filtered_z_rt %>%
  group_by(type, condition, valence) %>%
  summarise(z_rt_mean = mean(z_rt), z_rt_sd = sd(z_rt))


z_rtdat_lg <- lgdat %>%
  rename(valence = expression) %>%
  select(valence, condition, z_rt_mean, z_rt_sd, type)

z_rtdat_all <- rbind(z_rtdat_lg, data.frame(z_rtdat_model)) %>%
  mutate(type = fct_relevel(type, plot_groups))

if (use_tikz) {
  tikz(file = paste0(fig_path, "2backResponseTimeZ.tex"), width = 6, height = 3)
}

p <- ggplot(z_rtdat_all, aes(x = valence, y = z_rt_mean, group = type, fill= type)) +
  facet_grid(~condition, labeller = labeller(condition = c("break" = "break-set", match = "match-set", noset = "no-set", pers = "perseverance-set"))) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  scale_y_continuous() +
  geom_errorbar(aes(ymin=z_rt_mean-z_rt_sd, ymax=z_rt_mean+z_rt_sd), width=0.2, position = position_dodge(width = 0.9)) +
  labs(x = "Condition", y = "z-transformed mean RT") +
  fill_scale + 
  plot_theme

print(p)
if (use_tikz) {
  dev.off()
}

```

### ANOVA
```{r}
zrt_break <- behdat_filtered_z_rt %>%
  filter(condition == "break")

summary(aov(z_rt ~ (type * valence), data = zrt_break))

zrt_match <- behdat_filtered_z_rt %>%
  filter(condition == "match")

summary(aov(z_rt ~ (type * valence), data = zrt_match))

zrt_noset <- behdat_filtered_z_rt %>%
  filter(condition == "noset")

summary(aov(z_rt ~ (type * valence), data = zrt_noset))

zrt_pers <- behdat_filtered_z_rt %>%
  filter(condition == "pers")

summary(aov(z_rt ~ (type * valence), data = zrt_pers))

```

### Correlation with data
```{r}
zrt_model <- z_rtdat_model %>%
  arrange(type, condition, valence) %>%
  pull(z_rt_mean)

zrt_data <- z_rtdat_lg %>%
  arrange(type, condition, valence) %>%
  pull(z_rt_mean)

cor(zrt_model, zrt_data)
```

## Operator analysis
```{r}
op_files <- c()
op_files[1] <- tail(list.files(path = control_dir, pattern="ops.csv", full.names = TRUE),1)
op_files[2] <- tail(list.files(path = depressed_dir, pattern="ops.csv", full.names = TRUE),1)

opdat_full <- data.frame()
for (i in 1:length(op_files)) {
  opdat_full <- rbind(opdat_full, read.csv(op_files[i], header=TRUE,sep=","))
}

opdat <- opdat_full %>%
  select(-task_rep) %>%
  mutate(type = ifelse(model == levels(model)[1], model_names[1], model_names[2])) %>%
  mutate(on_task = as.logical(on_task), success = as.logical(success)) %>%
  select(-model)

```


### Frequency of mind-wandering: proportion of operators
```{r}
mw_freq <- opdat %>%
  group_by(type, participant, block, trial, on_task) %>%
  count(on_task) %>%
  group_by(type, participant, block, trial) %>%
  mutate(freq = n/sum(n)) %>%
  ungroup() %>%
  filter(on_task == FALSE) %>%
  mutate(freq = if_else(is.na(freq), 0, freq))


mw_share_of_ops <- mw_freq %>%
  group_by(type) %>%
  summarise(mw_mean = mean(freq), mw_sd = sd(freq))

mw_share_of_ops
```

### Frequency of mind-wandering: proportion of trials with >50% mind-wandering
```{r}
mw_dominant <- mw_freq %>%
  mutate(mw_trial = freq >= 0.5) %>%
  group_by(type) %>%
  count(mw_trial) %>%
  mutate(freq = nn/sum(nn))

mw_dominant
```

## Operator frequency
```{r}
op_freq <- opdat %>%
  filter(success == TRUE) %>%
  group_by(type, participant, operator, on_task) %>%
  count() %>%
  group_by(type, participant) %>%
  mutate(freq = n/sum(n)) %>%
  group_by(type, operator, on_task) %>%
  summarise(freq_mean = mean(freq), freq_sd = sd(freq))




ggplot(op_freq, aes(x = operator, y = freq_mean, group = desc(type), fill = type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  coord_flip() +
  facet_grid(on_task ~ ., scales = "free_y", switch = "both", as.table = FALSE, labeller = labeller(on_task = c("TRUE" = "Task operators", "FALSE" = "Mind-wandering operators"))) +
  scale_y_continuous() +
  geom_errorbar(aes(ymin=freq_mean-freq_sd, ymax=freq_mean+freq_sd), width=0.2, position = position_dodge(width = 0.9)) +
  labs(x = "Operator", y = "Frequency of use") +
  theme(axis.text.x = element_text(angle = 0, hjust = 0.5)) +
  fill_scale + 
  plot_theme

```
